{
    "config": {"start": "2025-09-02",
	       "end": "2025-12-12",
	       "days": ["W-MON", "W-WED"],
	       "hw_day": "W-FRI"},
    "class_sequence": [["What the class is about?", "intro"],
		       ["AI vs. NLP", "ai_nlp"],
		       ["Information Retrieval", "tfidf"],
		       ["Logistic Regression", "lr"],
		       "Continuing Logistic Regression / Homework Workshop",
		       ["Word representations", "word2vec"],
		       ["Pytorch", "pytorch"],
		       ["Homework Framework", "code"],
		       ["Syntax", "syntax"],
		       ["Linear neural language models (Last content on Midterm I)", "rnn"],
		       "Homework Workshop",
		       ["Transformers", "transformer"],
		       ["Decoding and Efficiency", "decoding-eff"],
		       ["Alignment", "alignment"],
		       ["Finetuning", "finetune"],
		       ["Machine translation", "mt"],
		       ["Midterm Review", "review"],
		       "Midterm I",
           "No Class: Makeup Midterm",
           "Zongxia Guest Lecture: Running Jobs on Nexus",
		       ["Question Answering Approaches, Datasets, and Eval", "qa"],
		       ["Item Response Theory", "irt"],
		       ["Adversarial Examples / Red Teaming", "adversarial"],
		       ["Midterm Review", "review"],
		       "Midterm II",
		       ["Expo Match", "expo"],
		       ["Ask Me Anything", "ama"],
		       ["Final Exam (for computers): 1:30pm - 3:30pm", "final"]],
    "hw_sequence": [["Warmup", "https://github.com/Pinafore/nlp-hw/tree/master/presidents"],
		    ["Tokenization and tf-idf", "https://github.com/Pinafore/nlp-hw/tree/master/tfidf"],
		    ["Logistic Regression", "https://github.com/Pinafore/nlp-hw/tree/master/lr_sgd_qb"],
		    ["Feature Engineering", "https://github.com/Pinafore/nlp-hw/tree/master/feateng"],
		    ["Sparse Retrieval", "https://github.com/Pinafore/nlp-hw/tree/master/tfidf_guesser"],
		    ["Pytorch LR + Adam", "https://github.com/Pinafore/nlp-hw/tree/master/lr_pytorch"],
		    "",
		    ["DAN", "https://github.com/Pinafore/nlp-hw/tree/master/dan"],
		    ["Transformer LM (Group)", "https://github.com/Pinafore/nlp-hw/tree/master/transformer"],
		    "",
		    ["Adversarial Authoring (Group)", "https://github.com/Pinafore/nlp-hw/tree/master/adversarial"],
		    ["LM Optimization (Group)", "https://github.com/Pinafore/nlp-hw/tree/master/llm_opt"]],
    "specials": ["2025-12-15"],
    "topics": {
  "intro": {
    "Content:": [
      ["Welcome to NLP", "https://youtu.be/2_2ttm1GHs4"],
      ["What's a word?", "https://youtu.be/ZqFqd9qUQM4"],
	["What's a language?", "https://youtu.be/YKfKfIXunyI"],
	["Tokenization", "https://youtu.be/lYVBXkuro1U"],
	["BPE", "https://youtu.be/3IAVyHCYY0E"]],
      "Administrivia:": [
      ["How to read this webpage", "https://youtu.be/5Og91_Cishs"],
      ["How to take a class with me", "https://youtu.be/AhVmt15x3k8"],
      ["More on the Flipped Classroom", "https://youtu.be/7JMOsWPmlMk"],
      ["Hybrid classes", "https://youtu.be/9oyZ3Wtcwtk"],
      ["Grader Expectations", "https://youtu.be/YEFMhYKOHmE"]
    ],
      "Readings:": [["SLP2", "https://web.stanford.edu/~jurafsky/slp3/2.pdf"],
		    ["Linguistic Fundamentals for Natural Language Processing: 100 Essentials from Morphology and Syntax (Chapters 1 and 2)",
        "https://www.morganclaypool.com/doi/abs/10.2200/S00493ED1V01Y201303HLT020"],
		  ["Alternate Link", "https://drive.google.com/file/d/1X_oc4E9asNjA5lxpiroA2c7dLgnyh4eD/view?usp=sharing"]
      ],
    "Optional Readings:": [
      ["Python (and programming) introductory course", "https://www.coursera.org/course/programming1"],
      ["Jon Hewitt's Math Notes", "https://www.cs.columbia.edu/~johnhew/coms4705/lectures/lec0.html"],
      ["First weeks of INST 414 as review", "../INST_414"],
      ["A probability primer", "http://www.sjsu.edu/faculty/gerstman/StatPrimer/probability.pdf"],
      ["Grinstead and Snell, Chapters 1-2, Chapter 4.1", "https://math.dartmouth.edu/~prob/prob/prob.pdf"],
	["How the statistical revolution changes (computational) linguistics", "http://aclweb.org/anthology/W/W09/W09-0103.pdf"],
	["The deep learning revolution in NLP", "https://aclanthology.org/J15-4006.pdf"],
	["How Much is Enough? The Diminishing Returns of Tokenization Training Data", "https://arxiv.org/abs/2502.20273"]
    ]
  },

  "ai_nlp": {
    "Videos:": [
      ["What's the difference between NLP, AI, and ChatGPT?", "https://youtu.be/4fek8n-xMZ4"],
      ["What made generative AI possible", "https://youtu.be/3qKYqtCzJMk"],
      ["What to call these models?", "https://www.youtube.com/watch?v=u0DgoRVLTE8&t=1s"],
      ["Shannon Game", "https://youtu.be/0shft1gokac"],
      ["Evaluating Language Models", "https://youtu.be/kdaX9p6Uc9k"],
      ["The Turing Test", "https://www.youtube.com/watch?v=bdQIUv9FutE"]
    ],
    "Optional Review:": [
      ["What are expectations and entropy?", "https://www.youtube.com/watch?v=O28U08_yaGU"]
    ],
    "administrivia": [
      ["Why you shouldn't use generative AI to cheat in my class", "https://youtu.be/a3w0ZquNFVs"]
    ],
    "Readings:": [
	["Language Models: A Guide for the Perplexed", "https://arxiv.org/abs/2311.17301"],
	["SLP3", "https://web.stanford.edu/~jurafsky/slp3/3.pdf"]
    ]
  },
	"adversarial": {
	    "There's no preparation needed for class on Monday, but please make sure to come with a device (and perhaps a pen and paper). We'll be trying to answer each others' adversarial questions.": [],
	    "Why it's important to come:":
	    [
		"This will be a practice for our final project",
		"This will count as 10 points on the adversarial HW",
		"You'll get a better intuition for how the final project works"
	    ]
	},
  "tfidf": {
    "Videos:": [
      ["The Cranfield Paradigm", "https://www.youtube.com/watch?v=L5cUjzjc_YE"],
      ["What is information retrieval?", "https://youtu.be/U6KgqeJkhU0"],
      ["TF-IDF", "https://youtu.be/A5ounv0D_cs"],
	["Evaluation", "https://youtu.be/BxAzuCSvF8s"],
	["RAG", "https://umd.hosted.panopto.com/Panopto/Pages/Viewer.aspx?id=02ac2ac7-cdc4-4964-a7c8-b38900b87539"]
    ],
    "Readings:": [
	["IR Chapter 1, 6", "https://nlp.stanford.edu/IR-book/"],
	["SLP 11.1", "https://web.stanford.edu/~jurafsky/slp3/11.pdf"],
	["Evolution of Cranfield (Optional)", "https://link.springer.com/chapter/10.1007/978-3-030-22948-1_2"]],
    "Slides:":
	    [["Cranfield", "https://docs.google.com/presentation/d/1cDnQ6dWvXqjYj2vrxn3S4yqq75TsPbfbT1YiYX4eBYI/edit?slide=id.p#slide=id.p"],
	    ["IR Intro", "01a_ir.pdf"],
	    ["IR tf-idf", "01b_tfidf.pdf"],
	     ["IR eval", "01c_evaluation.pdf"],
	     ["IR exercise", "tfidf_ex.pdf"]]
  },

  "lr": {
    "Videos:": [
      ["Regression", "https://www.youtube.com/watch?v=wy4ViG7uB1g"],
      ["Logistic Regression", "https://www.youtube.com/watch?v=9BcxOiwE4Ds"],
	["Stochastic Gradient Descent", "https://www.youtube.com/watch?v=8M-n8u2w2u8"],
      ["Feature Engineering in the Age of Deep Learning", "https://youtu.be/4-se75AuETA"],
      ["Feature Engineering for Quiz Bowl", "https://www.youtube.com/watch?v=IzKFgigocAg"]
    ],
      "Slides:": [
	  ["Logistic Regression w/ SGD", "lr_sgd.pdf"],
	  ["Example", "lr_ex.pdf"]
      ],
    "Readings:": [
	["SNLP Chapter 4", "https://web.stanford.edu/~jurafsky/slp3/4.pdf"]
    ]
  },
  "code": {
    "Videos:": [
      ["Advice / Overview", "https://share.descript.com/view/R4u9z3RyOuR?transcript=true"],
      ["How to stump a computer", "https://www.youtube.com/watch?v=6oZCIOBiSaI"],
      ["Good questions", "https://www.youtube.com/watch?v=uVcPlJu-JCM"],
      ["Bad questions", "https://youtu.be/LKQVJgj5ffg"]
    ],
    "optional_videos": [
      ["IRT", "https://www.youtube.com/watch?v=n4W4Gwwkbqg"]
    ],
    "optional_past_finals": [
      ["2019 Finals", "https://www.youtube.com/watch?v=vH8cUGFOwPk"],
      ["2022 Finals", "https://www.youtube.com/watch?v=dyaR7zT_KKg"]
    ]
  },

  "word2vec": {
    "Videos:": [
      ["Distributional Semantics", "https://youtu.be/vErGaMc80WM"],
      ["Word2Vec", "https://youtu.be/QyrUentbkvw"],
      ["Evaluation", "https://www.youtube.com/watch?v=Jid_EVBoVLU"]
    ],
    "Readings:": [
      ["SNLP Chapter 5 (formerly 6)", "https://web.stanford.edu/~jurafsky/slp3/5.pdf"]
    ],
      "Slides:": [
	  ["Distributional Semantics", "06a_distsim.pdf"],
	   ["Word2Vec", "06b_word2vec.pdf"],
	   ["Eval", "06c_eval.pdf"],
	   ["Exercise", "06d_ex.pdf"],
	   ["Exercise (Derivation)", "dist_derivation.pdf"]
	  ]
  },

  "syntax": {
    "Videos:": [
      ["What's a part of speech, and why is it a joint problem?", "https://youtu.be/3Aklvuq514M"],
	["Hidden Markov Modeling", "https://youtu.be/0gu1BDj5_Kg"],
	["Constituency grammars", "https://www.youtube.com/watch?v=xNHWhQrHeMU"],
	["Dependency parsing", "https://youtu.be/ZT1Et5wd1SQ"]
    ],
    "Readings:": [
      ["SNLP Chapters 17.1 and 17.2", "https://web.stanford.edu/~jurafsky/slp3/17.pdf"],
	  ["SNLP Chapter 18.1 - 18.3", "https://web.stanford.edu/~jurafsky/slp3/18.pdf"],
	  ["SNLP Chapter 19.1 - 19.2", "https://web.stanford.edu/~jurafsky/slp3/19.pdf"]
    ],
      "Slides": [
	  ["Sequence Modeling", "sequence.pdf"],
	  ["HMM", "10a_hmm.pdf"],
	  ["Constituency grammars", "12a_pcfg.pdf"],
	  ["Dependency", "parsing_dependency.pdf"],
	  ["HMM Ex", "10c_ex.pdf"],
	  ["PCFG Ex", "12a_pcfg.pdf"],
	  ["Dependency Ex", "dependency_ex.pdf"]],
    "Optional Lectures": [
	["Viterbi Algorithm", "https://youtu.be/cGjWlHO1x6U"],
	["PCFGs", "https://www.youtube.com/watch?v=itJXYgkHwUo"],
	["CYK Parsing", "https://www.youtube.com/watch?v=O-x3krZ3A-Q"],
      ["Shift-Reduce Parser", "https://www.youtube.com/watch?v=f5-hTA9hA3s"]
    ]
  },
	"review": {
	    "Slides": [
		["Midterm I", "midterm_1_review.pdf"],
		["Midterm II", "llm_midterm_review.pdf"]
		]
	},
  "pytorch": {
    "Videos:": [
      ["Deep", "https://www.youtube.com/watch?v=-XSPumV6v00"],
      ["Backprop", "https://www.youtube.com/watch?v=QRUfFGfImhg"],
      ["Frameworks", "https://youtu.be/FJQl0ujTAGw"],
      ["Pytorch", "https://youtu.be/AZwwDIV2vcI"],
	["DAN", "https://youtu.be/losFCNJbnZY"],
	["ADAM", "https://youtu.be/ascWFMmSF2w"]
    ],
    "Readings:":
      [["SNLP Chapter 6 (Was 6)", "https://web.stanford.edu/~jurafsky/slp3/6.pdf"]],
      "Slides:":
      [["Deep", "05a_deep.pdf"],
       ["Backprop", "05b_backprop.pdf"],
       ["Frameworks", "05c_compgraph.pdf"],
       ["Pytorch", "05d_code_ex.pdf"],
       ["DAN", "05e_dan.pdf"],
       ["ADAM", "lr_adam.pdf"],
       ["Exercise", "https://docs.google.com/presentation/d/1IcW5iMPa-sYc0wgLGZWByQ5L1Kg1nt_ti34Jspfzqo4/edit?usp=sharing"]
      ]
  },
  "rnn": {
      "Videos:": [
	  "Continuous BOW for Sentiment",
      ["RNN for Sentiment", "https://youtu.be/h4yA7f8o1fM"],
      ["RNN for LM", "https://youtu.be/KfaA5BC0Fus"],
        ["LSTM", "https://www.youtube.com/watch?v=nIVO2e9lZ84"],
        ["Backpack", "https://share.descript.com/view/4NlyC8fMhYg"],
	["Sequence models in Pytorch", "https://umd.hosted.panopto.com/Panopto/Pages/Viewer.aspx?id=348d7b77-21c8-421e-a068-b1410008fcbb"]
    ],
    "Readings:": [
      ["SNLP 19 (Was 9)", "https://web.stanford.edu/~jurafsky/slp3/19.pdf"]
    ],
      "Optional Readings:":
      [
          ["Backpack LM", "https://arxiv.org/abs/2305.16765"]
      ],
      "Slides:": [
          ["RNN sentiment", "nlm_rnn_sentiment.pdf"],
          ["RNN LM", "nlm_rnn_lm.pdf"],
          ["LSTM", "lstm.pdf"],
          ["RNN Exercise", "nlm_rnn_hand.pdf"]
      ],
      "Optional Videos:":
      [      ["LSTM", "https://www.youtube.com/watch?v=nIVO2e9lZ84"] ]
  },
  "transformer": {
    "Videos:": [
      ["Contextual Neural Language Models Overview", "https://www.youtube.com/watch?v=KHpM3UXdMxM&t"],
      ["Transformer Encoder", "https://youtu.be/9Z7mN7ebWDA"],
      ["BERTology", "https://youtu.be/YgfE-9N7Rio"],
      ["Decoder", "https://youtu.be/ORzGEnHTSfk"],
      ["Implementation Details", "https://youtu.be/RTuW3r83c5E"]
    ],
    "Readings:": [
      ["SNLP 8", "https://web.stanford.edu/~jurafsky/slp3/8.pdf"],
      ["SNLP 7-7.3", "https://web.stanford.edu/~jurafsky/slp3/8.pdf"]
    ],
			       "Optional Readings": [["Annotated Transformer", "https://nlp.seas.harvard.edu/annotated-transformer/"],
						     ["Illustrated Transformer", "https://jalammar.github.io/illustrated-transformer/"],
						     ["Transformer in an Excel Spreadsheet", "https://github.com/ImagineAILab/ai-by-hand-excel/blob/main/advanced/Transformer.xlsx"]],
                               "Topics": [["Muppet Models", "https://users.umiacs.umd.edu/~jbg/teaching/CMSC_723/18a_nlm.pdf"],
                               ["Attention w/ Backpacks", "nlm_backpack_attention.pdf"],
                                          ["Transformers", "https://docs.google.com/presentation/d/1Wmte5rM9qgN-JHq34LFX8y3G2HebHKWRV9iu-p_fC2k/edit?usp=sharing"],
                                          ["Induction Head Exercise", "induction_head.pdf"]]
  },
	"alignment": {
    "Slides:": [
		["Alignment + RLHF", "https://docs.google.com/presentation/d/1stZij7ztz5bXAk4hNqbLK_F-ufFxu6heVznBoyHs6Mo/edit?usp=sharing"],
      ["RL Review", "***"],
	["Policy Gradient", "../CMSC_848/rl_policy_gradient.pdf"],
	["Gricean Exercise", "alignment_grice.pdf"]
    ],
    "Videos:": [
		["Alignment", "https://umd.hosted.panopto.com/Panopto/Pages/Viewer.aspx?id=39553dee-1346-4150-bec6-b37b0163ed2b"],
      ["RL Review", "https://umd.hosted.panopto.com/Panopto/Pages/Viewer.aspx?id=84c5e59c-d803-4cf8-8d0a-b37b01596539"],
      ["Policy Gradient", "https://umd.hosted.panopto.com/Panopto/Pages/Viewer.aspx?id=655d5f9f-eba9-45f8-90e3-b37b01596533"],
	["RLHF", "https://umd.hosted.panopto.com/Panopto/Pages/Viewer.aspx?id=a578c99f-5468-44f0-a0ab-b37b01596533"]
    ],
    "Readings:": [
	  ["SLP 9", "https://web.stanford.edu/~jurafsky/slp3/9.pdf"],
      ["Open Problems and Fundamental Limitations of Reinforcement Learning from Human Feedback", "https://liralab.usc.edu/pdfs/publications/casper2023open.pdf"]
    ]
  },
  "qa": {
    "Videos:": [
      ["Dense Retrieval", "https://www.youtube.com/watch?v=w9eylxli07U"],
      ["BERT for MRQA", "https://youtu.be/b38opGM9R2w"],
      ["Multihop", "https://www.youtube.com/watch?v=YwdEK2NowNM"],
      ["Watson on Jeopardy!", "https://youtu.be/WCIFUJ5oeRA"],
      ["Cranfield vs. Manchester", "https://www.youtube.com/watch?v=9peCcstwGtU"]
    ],
      "Slides": [
	  ["Dense Retrieval", "https://docs.google.com/presentation/d/17g-FG5jqvhQVGSkLI1BH3d7T2prTGTHcd3CeG7EDeVA/edit?usp=sharing"],
	  ["Multihop", "https://docs.google.com/presentation/d/1f8et7rYOD9WvDiVLNN2W1THK54YWdiC5gQPrxddfVSQ/edit?usp=sharing"],
	  ["Watson", "https://docs.google.com/presentation/d/13Cb7Bxz2NUGOPlO9ydAlpX1Y-zTcCo6k-wBvISPiruM/edit?usp=sharing"],
	  ["Manchester vs. Cranfield", "https://docs.google.com/presentation/d/1cDnQ6dWvXqjYj2vrxn3S4yqq75TsPbfbT1YiYX4eBYI/edit?usp=sharing"],
	  ["Exercise", "qa.pdf"]
      ],
    "Readings:": [
      ["MRC Literature Review", "https://www.cambridge.org/core/journals/natural-language-engineering/article/survey-on-machine-reading-comprehension-systems/23FBCE30CB4325538E7DD08A7924315F"],
	["SLP (old edition) --- Ignore IR review", "https://web.stanford.edu/~jurafsky/slp3/old_dec21/23.pdf"]
    ]
  },
	"irt": {"Videos:": [
		["Standardized Tests", "https://youtu.be/_pjXLtF4k18"],
		["IRT", "https://youtu.be/n4W4Gwwkbqg"],
	    ["IRT for Leaderboards", "https://youtu.be/Mg-WHxUWZxc"],
	    ["Multiple Choice", "https://www.youtube.com/watch?v=DnMOZ7DAZA8"]],
		"Slides:": [["Multiple Choice", "https://docs.google.com/presentation/d/1RrjTVAyJyvSHc0HDFO2gIr87KHAy67kNbpbEvawi8IQ/edit?usp=sharing"],
			    ["Standardized + IRT", "https://docs.google.com/presentation/d/1G__eKLOwbV7MtOAh0FH1SxSIIO0HoRuCT8sNHBcdCyU/edit?usp=sharing"],
			    ["Exercise", "irt_ex.pdf"]],
		"Readings:":
		[["A visual guide to IRT", "https://www.stat.cmu.edu/~brian/PIER-methods/For%202013-02-28/Readings/Interactive%20pdf%20on%20Item%20Response%20Theory.pdf"]],
		"Optional Readings:":
		[["IRT Tutorial (Useful for reference list)", "https://aclanthology.org/2024.eacl-tutorials.2.pdf"]]
	       },
	        "decoding-eff": {
		    "Videos:": [["All Videos (Descript)", "https://share.descript.com/view/rUNTEGXn4xN"], ["Qantization", "https://youtu.be/FUaYrAe5CGg"], "Mixture of Experts",
				["Speculative Decoding", "https://youtu.be/VnvhD8_E7AQ"],
				["KV Caching", "https://youtu.be/_quDGLpNols"]],
            "Slides:": [["Qantization", "opt_quantization.pdf"], ["Mixture of Experts", "opt_moe.pdf"], ["Speculative Decoding", "opt_speculative.pdf"], ["KV Caching", "https://docs.google.com/presentation/d/1I40CPUt2Wn-UXzwAEOyMzSkPG6KvFUEnrwGtLXcFoHA/edit?usp=sharing"]],
	    "Reading:": [["Efficient Large Language Models: A Survey (LoRA bit is relevant for later class)", "https://arxiv.org/pdf/2312.03863"]]
        },
                "finetune": {
                    "Videos:": [["Prompting: What is it good for?", "https://youtu.be/hyUeko4GLxo"],
				["DSPY Example", "https://youtu.be/sG3Tz0-Vw58"],
				["QLoRA", "https://youtu.be/UXa6Uf8TluU"]],
                    "Slides:": [["Promespting", "https://docs.google.com/presentation/d/1BFLbysrNj1281ERzVU7EOmT3IwnujN3-twxPzvSMwjU/edit?usp=sharing"], ["DSPy Example", "finetune_dspy.pdf"], ["QLoRA", "finetune_lora.pdf"], ["LoRA Ex", "lora.pdf"]],
		    "Optional Reading:": [["SIMBA", "https://blog.mariusvach.com/posts/dspy-simba"]],
    "optional_videos": [
      ["UG Research at UMD on Prompting", "https://www.youtube.com/watch?v=cmge3fFfZMc"]
    ]
                },
  "mt": {
    "Videos:": [
      ["Translation is Hard", "https://youtu.be/XLBUsH-ImyI"],
      ["Word-based Translation", "https://www.youtube.com/watch?v=seFL2wjOmRw&t=3s"],
      ["Phrase-based Translation", "https://www.youtube.com/watch?v=vH7tmUOZVIg"],
      ["Neural Machine Translation", "https://umd.hosted.panopto.com/Panopto/Pages/Viewer.aspx?id=e91ba8c5-abd2-4ca3-a794-b384000409f3"],
      ["Decoding", "https://umd.hosted.panopto.com/Panopto/Pages/Viewer.aspx?id=cee39581-431a-4cc4-92fc-b384000409e8"],
      ["Evaluation", "https://youtu.be/BhOL5ztG1-Y"]
    ],
"Lectures": [["What is MT, why is it hard, how is it evaluated?", "https://docs.google.com/presentation/d/1iqYBCI23a8SeSFAgX_R328dn2vioY717Zg9hyA0w4vk/edit?usp=sharing"],
                                   ["Word-based Models", "mt_model1.pdf"],
                                   ["Phrase-based Models", "mt_phrase.pdf"],
                                   ["Neural", "mt_neural.pdf"],
             ["Decoding", "mt_decoding.pdf"],
	     ["Nucleus Sampling Exercise", "nucleus_sampling.pdf"]
      ],
    "Readings:": [
      ["NMT Book (Chapter 5)", "http://mt-class.org/jhu/assets/nmt-book.pdf"]
    ]
  },
  "ama": {
    "Videos:": [
      ["Course Evals", "https://www.youtube.com/watch?v=_4UX8ep97NU"],
      ["You got a PhD in Computational Linguistics ... what now?", "https://youtu.be/3e6TchIg55k"],
      ["Optimizing ML for Society", "https://www.youtube.com/watch?v=BuESxqQwgmw"],
      ["How far off were my predictions? and p(Doom)", "https://www.youtube.com/watch?v=5AoB-00u7-c"]
    ]
  },
	"final": {
	    "How this will work:":
	    ["You'll arrive",
	     "You'll be given three possible themes for writing a question",
	     "You'll pick one of them",
	     "You'll write a multiple choice question on paper over the course of an hour",
	     "You'll turn in your paper multiple choice question on paper",
	     "You'll then be able to enter the same question on a device to turn it in",
	     "We'll then have a break to prepare the questions for everyone to answer",
	     "You'll then try to answer the questions that people wrote"],
	    "Your score for the question will be the delta between computer difficulty and human difficulty for the question (as measured by IRT).": []
	}
}
}
