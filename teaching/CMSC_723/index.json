{
    "config": {"start": "2024-08-26",
	       "end": "2024-12-09",
	       "days": ["W-MON", "W-WED"],
	       "hw_day": "W-FRI"},
    "topics": {"intro": {"Readings": ["Speech and Language Processing Chapter 1"],
                         "Topics": [["What is the course about?", "intro_grad_nlp.pdf"], "Structure of the course (nhf)", ["Discussion of co-teaching / pedagogy / delivery (jbg)", "intro_howto.pdf"], ["Linguistic Background (nhf)", "https://drive.google.com/file/d/1EPlajskGIQ0Y5Dl0TwptCC9XeHHSbgcV/view?usp=sharing"], ["Programming Background (jbg)", "intro_python.pdf"], ["Math Background (jbg)", "intro_math.pdf"]],
			 "Optional Readings (Background)": [["Python (and programming) introductory course", "https://www.coursera.org/course/programming1"],
							    ["Statistics review (first few weeks)", "../INST_414"],
							    ["Probability primer", "http://www.sjsu.edu/faculty/gerstman/StatPrimer/probability.pdf"],
							    ["How the statistical revolution changed (computational) linguistics", "http://aclweb.org/anthology/W/W09/W09-0103.pdf"],
							    ["Deep learning revolution", "https://aclanthology.org/J15-4006/"]],
			 "Math Review Videos": [["Functions", "https://youtu.be/MjeXZ7Ea89g"],
					 ["Distributions", "https://youtu.be/qc5QewourIU"],
					 ["Vectors", "https://youtu.be/kXLGnrzw1zk"],
					 ["Matrix math", "https://youtu.be/LEJpb8v_RQQ"],
					 ["Gradients and Optimization", "https://youtu.be/TG6PIKulK0Q"]]},
	       "ling_prelim": {"Readings": [["Jackendoff Patterns in the Mind Chapter 6", "https://drive.google.com/file/d/1gczrF1tDyErmvcanDj_iw1fLMeYhILwJ/view?usp=sharing"], ["Language Files Chapter 4", "https://drive.google.com/file/d/1NhJrY062aZ0nv2BpozZlKJV5geFuAAhs/view?usp=drive_link"], ["Language Files Chapter 6.6", "https://drive.google.com/file/d/12OazqK-bV1ss59JjS4siNJpnDle0EJPs/view?usp=drive_link"]],
		         "Optional Readings (Reference)": [["Bender Linguistic Fundamentals for Natural Language Processing", "https://drive.google.com/file/d/1X_oc4E9asNjA5lxpiroA2c7dLgnyh4eD/view?usp=sharing"]],
			 "Topics": [["Linguistic analysis", "https://drive.google.com/file/d/14jy7xfp3eX3EHwTbOrRQa8Lbg77n5Vw-/view?usp=sharing"], "Syntax", "Morphology", "Types and tokens"]},
	       "lm": {"Readings": [["SLP3 Chapter 3", "https://web.stanford.edu/~jurafsky/slp3/3.pdf"]],
		      "Optional Readings (Background)": [["An Empirical Study of Smoothing Techniques for Language Modeling", "https://aclanthology.org/P96-1041/"],
							 ["Prediction and Entropy of Printed English", "https://languagelog.ldc.upenn.edu/myl/Shannon1950.pdf"],
							 ["A Bayesian Interpretation of Interpolated Kneser-Ney", "https://www.stats.ox.ac.uk/~teh/research/compling/hpylm.pdf"]],
		      "Topics": [["Bigram Language Models", "lm_bigram.pdf"],
				 ["Evaluation", "lm_perplexity.pdf"],
				 ["Backoff", "lm_crp.pdf"]],
		      "Videos": [["Bigram Language Models", "https://www.youtube.com/watch?v=rO80BH5FI3s"],
				 ["Shannon Game", "https://www.youtube.com/watch?v=0shft1gokac"],
				 ["Perplexity", "https://www.youtube.com/watch?v=kdaX9p6Uc9k"],
				 ["Backoff", "https://www.youtube.com/watch?v=4wa2WyDrgMA"]
				]},
	       "pytorch": {"Readings": [["SLP3 Chapter 7", "https://web.stanford.edu/~jurafsky/slp3/7.pdf"],
					["Pytorch Tutorial", "https://pytorch.org/tutorials/beginner/basics/intro.html"]],
			   "Topics": [["Deep Learning", "deep_intro.pdf"],
				      ["XOR", "deep_xor_ex.pdf"],
				      ["Pytorch", "deep_compgraph.pdf"],
				      ["Logreg", "deep_logreg.pdf"],
				      ["DAN in Pytorch", "deep_dan.pdf"]
				     ],
			   "Videos": [["Deep Learning", "https://www.youtube.com/watch?v=-XSPumV6v00"],
				      ["Backprop", "https://www.youtube.com/watch?v=QRUfFGfImhg"],
				      ["Frameworks", "https://youtu.be/FJQl0ujTAGw"],
				      ["Pytorch", "https://youtu.be/AZwwDIV2vcI"],
				      ["DAN", "https://youtu.be/losFCNJbnZY"]
				     ]},
	       "word2vec": {"Readings": [["SLP 6", "https://web.stanford.edu/~jurafsky/slp3/6.pdf"]],
			    "Optional Readings": [["Neural Word Embedding as Implicit Matrix Factorization", "https://proceedings.neurips.cc/paper_files/paper/2014/file/feab05aa91085b7a8012516bc3533958-Paper.pdf"],
						  ["GloVe", "https://nlp.stanford.edu/projects/glove/"]],
			    "Topics": [["Distributional and Distributed Representations", "dist_intro.pdf"],
				       ["Sparse Representations", "dist_sparse.pdf"],
				       ["Word2Vec", "dist_word2vec.pdf"],
				       ["Training Distributional Models", "dist_train.pdf"]],
			    "Videos": [["Distributed/Distributional Representations", "https://youtu.be/vErGaMc80WM"],
				       ["word2vec algorithm", "https://youtu.be/QyrUentbkvw"],
				       ["tf-idf", "https://youtu.be/A5ounv0D_cs"]
				      ]},
	       "rnn": {"Readings": [["SLP3 Chapter 8", "https://web.stanford.edu/~jurafsky/slp3/8.pdf"]],
		       "Optional Readings": [["Backpack LMs", "https://aclanthology.org/2023.acl-long.506.pdf"]],
		       "Topics": [["RNN for Sentiment", "nlm_rnn_sentiment.pdf"],
				  ["RNN for LM", "nlm_rnn_lm.pdf"],
				  ["RNN in Pytorch", "https://docs.google.com/presentation/d/14Hn7L1JToc3H6SW6dsv7ldWYLIlI5iz4H_iduGzedGg/edit?usp=sharing"],
				  ["LSTM", "nlm_lstm.pdf"],
				  ["Backpack LM", "nlm_backpack_sentiment.pdf"]],
		       "Videos": [["RNN for Sentiment", "https://youtu.be/h4yA7f8o1fM"],
				  ["RNN for LM", "https://youtu.be/KfaA5BC0Fus"],
				  ["LSTM", "https://www.youtube.com/watch?v=nIVO2e9lZ84"],
				  ["RNN in Pytorch", "https://umd.hosted.panopto.com/Panopto/Pages/Viewer.aspx?id=348d7b77-21c8-421e-a068-b1410008fcbb"]]},
	       "transformer": {"Readings": [["SLP 9", "https://web.stanford.edu/~jurafsky/slp3/9.pdf"]],
			       "Optional Readings": [["Annotated Transformer", "https://nlp.seas.harvard.edu/annotated-transformer/"],
						     ["Illustrated Transformer", "https://jalammar.github.io/illustrated-transformer/"],
						     ["Transformer in an Excel Spreadsheet", "https://github.com/ImagineAILab/ai-by-hand-excel/blob/main/advanced/Transformer.xlsx"]],
                               "Topics": [["Muppet Models", "https://users.umiacs.umd.edu/~jbg/teaching/CMSC_723/18a_nlm.pdf"],
                               ["Attention w/ Backpacks", "nlm_backpack_attention.pdf"],
                                          ["Transformers", "https://docs.google.com/presentation/d/1Wmte5rM9qgN-JHq34LFX8y3G2HebHKWRV9iu-p_fC2k/edit?usp=sharing"]],
                               "Videos": [["Muppet Models", "https://www.youtube.com/watch?v=KHpM3UXdMxM&t"],
                                          ["Encoder", "https://youtu.be/9Z7mN7ebWDA"],
                                          ["BERTology", "https://youtu.be/YgfE-9N7Rio"],
                                          ["Decoder", "https://youtu.be/ORzGEnHTSfk"]                                         ]},
	       "speech": {"Readings": [["SLP3 Chapter 16 p. 1-11", "https://web.stanford.edu/~jurafsky/slp3/16.pdf"]],
			 "Optional Readings (Background)": [["Phonetics", "https://web.stanford.edu/~jurafsky/slp3/H.pdf"]],
			 "Topics": [["Waveforms", "https://drive.google.com/file/d/1Gi3T3vhGH3mDBn7Om7azpMlmLrAtCMKd/view?usp=sharing"], "Spectrograms", "Formants", "MFCCs"],
	       	         "Resources": [["IPA chart", "https://www.internationalphoneticalphabet.org/ipa-sounds/ipa-chart-with-sounds/"]]},
	       "decoding": {"Readings": [["SLP3 Chapter 10", "https://web.stanford.edu/~jurafsky/slp3/10.pdf"]],
			"Topics": [["Self-attention", "https://drive.google.com/file/d/1s-op5ojy1xMUQgCVeBR_igBuzyj2FhVa/view?usp=sharing"], "Masked attention", "Risks", "Strategies for analyzing representations"]},
               "muppet models": {"Readings": [["SLP3 Chapter 12", "https://web.stanford.edu/~jurafsky/slp3/12.pdf"]],
                                 "Topics": [["RL Review", "alignment_rl.pdf"],
                                            ["Feedback for LMs", "alignment_feedback.pdf"],
                                            ["Alignment Datasets", "alignment_datasets.pdf"],
                                            ["DPO", "alignment_dpo.pdf"],
                                            ["Implementation Details", "https://docs.google.com/presentation/d/1Wmte5rM9qgN-JHq34LFX8y3G2HebHKWRV9iu-p_fC2k/edit?usp=sharing"]
                                            ],
                                 "Videos": ["RL Review",
                                            "Alignment",
                                            "Policy Gradient",
                                            "RLHF",
                                            ["Implementation", "https://youtu.be/RTuW3r83c5E"]]
                                },
               "prompting and tuning": {"Readings": [["Prompting Survey", "https://arxiv.org/abs/2406.06608"],
                                                     ["LoRA", "https://arxiv.org/pdf/2106.09685"]],
                                        "Topics": [["Fine-Tuning", ""],
                                                   ["LoRA", ""],
                                                   ["Prompt Optimization", ""],
                                                   ["Why Muppet Models", "https://docs.google.com/presentation/d/1fV5EbqDUmqmNs9NoFt21jNypo3qhUa0pxWmTSncefyk/edit?usp=sharing"]]
                                       },
	       "classification": {"Readings": [["SLP Chapter 5", "https://web.stanford.edu/~jurafsky/slp3/5.pdf"]],
			"Topics": [["Logistic regression", "https://drive.google.com/file/d/1qYeKKRAGbrBsSARR7VNe3U3sELmN0N4G/view?usp=drive_link"], "Training and test data", "Loss functions", "Gradient descent"]}
	      },
    "class_sequence": [["What the class is about", "intro"],
		       ["What's a sentence, morpheme, type, token, word, etc. (nhf)", "ling_prelim"],
		       ["Classical language models (jbg)", "lm"],
		       ["What's in the speech signal (nhf)", "speech"],
		       ["Classification and evaluation (nhf)", "classification"],
		       ["Pytorch and Logistic Regression (jbg)", "pytorch"],
		       ["Learning word representations (jbg)", "word2vec"],
		       ["Linear neural language models (jbg)", "rnn"],
		       ["Transformers (jbg)", "transformer"],
		       ["Decoding (nhf)", "decoding"],
		       ["Alignment (jbg)", "alignment"],
		       ["Neural ASR (nhf)", "neuralasr"],
		       ["Prompting and Fine-Tuning (jbg)", "prompting and tuning"],
		       ["Structure in language: HMMs and PCFGs (nhf)", "pcfg"],
		       ["Syntax: Dependency Grammars (nhf)", "dep"],
		       ["Semantics (nhf)", "semantics"],
		       ["Coreference (nhf)", "coref"],
		       ["Machine translation (jbg)", "mt"],
		       ["Reviewing (jbg)", "reviewing"],
		       ["Question Answering (jbg)", "qa"],
		       ["Writing a Paper (jbg)", "writing"],
		       ["Midterm Review (TA)", ""],
		       ["Midterm (TA)", ""],
		       ["Modeling human Sentence Processing (nhf)", "cog-sentence"],
		       ["Modeling human Speech Perception (nhf)", "cog-speech"],
		       ["Multimodal (jbg)", "multimodal"],
		       ["Annotation (nhf)", "annotation"],
		       ["Careers in NLP / AUA", "careers"],
			["Poster day", ""]],
    "hw_sequence": [["Limerick", "https://github.com/Pinafore/cl1-hw/tree/master/limerick"],
		     "",
		    ["Bigram Language Model", "https://github.com/Pinafore/cl1-hw/tree/master/bigram_lm"],
		    ["Classification", "https://github.com/Pinafore/cl1-hw/tree/master/lr_speech"],
		    "",
		    ["Feature Engineering", "https://github.com/Pinafore/cl1-hw/tree/master/feateng"],
		    ["DAN", ""],
		    ["Neural ASR", ""],
		    ["Project Proposal", ""],
		    ["Syntax", ""],
		    ["Paper Review", ""],
		    "",
		    ["Project Deliverable", ""],
		    ["Poster", ""]],
    "specials": ""
}
